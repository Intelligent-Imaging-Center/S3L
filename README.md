# S3L

<h1 align="center"> Leveraging Spatiotemporal Cues for Self-Supervised Stereo Depth Estimation in Endoscopic Videos </h1>

We have released the segmentation configurations and loading scripts for the SCARED dataset in advance.

## ğŸ“ Checklist

- â¬› Upload data processing code
- â¬› Upload inference code 
- â¬› Upload Upload pre-trained weights  
- â¬› Upload training code  

## ğŸ›  Installation
1. First you have to make sure that you clone the repo with the `--recursive` flag.
```bash
git clone --recursive https://github.com/Intelligent-Imaging-Center/S3L.git
cd S3L
```
2. Creating a new conda environment.
```bash
conda create --name s3l python=3.9
conda activate s3l
```
3. Install CUDA 11.8 and torch-related pacakges
```bash
pip install numpy==1.25.0 # do not use numpy >= v2.0.0
conda install --channel "nvidia/label/cuda-11.8.0" cuda-toolkit
pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118
```
4. Now install the other requirements
```bash
conda env update -f environment.yml --prune
```
### Basic Dependencies:
- CUDA Version >= 11.8
- Python >= 3.8
- Pytorch >= 2.0.0

## ğŸ“ Dataset Preparation
We excluded subsets D4 and D5 of the SCARED dataset due to severe calibration inaccuracies and temporal misalignment. The remaining subsets were split as follows: D1â€“D3 and D6â€“D7 were used for training, yielding 19 videos with a total of 17,206 frames. D8 and D9 were reserved for testing, providing 8 videos with 5,907 frames.

Please refer to [this](https://github.com/EikoLoki/MICCAI_challenge_preprocess) to prepare your SCARED data.
```bash
The folder structure is as follows:
scard/
â”œâ”€â”€ dataset_1/
â”‚   â”œâ”€â”€ keyframe_1/
â”‚   â”‚   â”œâ”€â”€ disp/
â”‚   â”‚   â”œâ”€â”€ left_finalpass/
â”‚   â”‚   â””â”€â”€ right_finalpass/
â”‚   â”œâ”€â”€ keyframe_2/
â”‚   â”œâ”€â”€ keyframe_3/
â”‚   â””â”€â”€ keyframe_4/
â”œâ”€â”€ dataset_2/
â”‚   â”œâ”€â”€ keyframe_1/
â”‚   â”œâ”€â”€ keyframe_2/
â”‚   â””â”€â”€ keyframe_3/
...
â””â”€â”€ dataset_9/
    â”œâ”€â”€ keyframe_1/
    â”œâ”€â”€ keyframe_2/
    â””â”€â”€ keyframe_3/
```
## âœ¨ Quick Test:
preparing trained modelï¼šWe will release the pre-trained model soon.
start testing single Image
```bash
python eval_img.py --load_weights path/to/your/weights/folder --image_path path/to/your/test/image
```
start testing vedio
```bash
python eval_vedio.py --load_weights path/to/your/weights/folder --vedio_path path/to/your/test/vedio
```
## ğŸ–‹ Train:
```bash
python train.py --data_path path/to/your/data --output_name mytrain --config configs/scared/d1/k1.yaml
```
